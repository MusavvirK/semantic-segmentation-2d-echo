{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ThesisV3.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0f68NiieJFn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "outputId": "8c514848-189b-4f5d-8afa-45b02f8dd6bd"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sFkM3iDTeYke",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "71441e22-14a6-4dce-abe5-6da3731931bd"
      },
      "source": [
        "cd /content/drive/My Drive/echo/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/echo\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-eNwUb-X_kc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "outputId": "0181e929-3168-450f-8e86-b025e0093b7a"
      },
      "source": [
        "!pip install simpleITK"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting simpleITK\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f8/d8/53338c34f71020725ffb3557846c80af96c29c03bc883551a2565aa68a7c/SimpleITK-1.2.4-cp36-cp36m-manylinux1_x86_64.whl (42.5MB)\n",
            "\u001b[K     |████████████████████████████████| 42.5MB 108kB/s \n",
            "\u001b[?25hInstalling collected packages: simpleITK\n",
            "Successfully installed simpleITK-1.2.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9GFHEV9-lEL-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "942f8988-b1aa-404a-e0cb-2e3d0554be40"
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sPPT9BjICvHd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "87571b45-d52a-42f5-8e62-810869a56136"
      },
      "source": [
        "from glob import glob\n",
        "import numpy as np\n",
        "import os\n",
        "import skimage.io as io\n",
        "from PIL import Image\n",
        "from prefetch_generator import background\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import random\n",
        "\n",
        "NUM_PREFETCH = 10\n",
        "RANDOM_SEED = 123\n",
        "\n",
        "\n",
        "class DataLoaderCamus:\n",
        "    def __init__(self, dataset_path, input_name, target_name, condition_name,\n",
        "                 img_res, target_rescale, input_rescale, condition_rescale, train_ratio, valid_ratio,\n",
        "                 labels, augment):\n",
        "        self.dataset_path = dataset_path\n",
        "        self.img_res = tuple(img_res)\n",
        "        self.target_rescale = target_rescale\n",
        "        self.input_rescale = input_rescale\n",
        "        self.condition_rescale = condition_rescale\n",
        "        self.input_name = input_name\n",
        "        self.target_name = target_name\n",
        "        self.condition_name = condition_name\n",
        "        self.augment = augment\n",
        "\n",
        "        patients = sorted(glob(os.path.join(self.dataset_path, 'training', '*')))\n",
        "        random.Random(RANDOM_SEED).shuffle(patients)\n",
        "        num = len(patients)\n",
        "        num_train = int(num * train_ratio)\n",
        "        num_valid = int(num_train * valid_ratio)\n",
        "\n",
        "        self.valid_patients = patients[:num_valid]\n",
        "        self.train_patients = patients[num_valid:num_train]\n",
        "        self.test_patients = patients[num_train:]\n",
        "        if train_ratio == 1.0:\n",
        "            self.test_patients = glob(os.path.join(self.dataset_path, 'testing', '*'))\n",
        "        print('#train:', len(self.train_patients))\n",
        "        print('#valid:', len(self.valid_patients))\n",
        "        print('#test:', len(self.test_patients))\n",
        "\n",
        "        all_labels = {0, 1, 2, 3}\n",
        "        self.not_labels = all_labels - set(labels)\n",
        "\n",
        "        data_gen_args = dict(rotation_range=augment['AUG_ROTATION_RANGE_DEGREES'],\n",
        "                             width_shift_range=augment['AUG_WIDTH_SHIFT_RANGE_RATIO'],\n",
        "                             height_shift_range=augment['AUG_HEIGHT_SHIFT_RANGE_RATIO'],\n",
        "                             shear_range=augment['AUG_SHEAR_RANGE_ANGLE'],\n",
        "                             zoom_range=augment['AUG_ZOOM_RANGE_RATIO'],\n",
        "                             fill_mode='constant',\n",
        "                             cval=0.,\n",
        "                             data_format='channels_last')\n",
        "        self.datagen = ImageDataGenerator(**data_gen_args)\n",
        "\n",
        "    def read_mhd(self, img_path, is_gt):\n",
        "        if not os.path.exists(img_path):\n",
        "            return np.zeros(self.img_res + (1,))\n",
        "        img = io.imread(img_path, plugin='simpleitk').squeeze()\n",
        "        img = np.array(Image.fromarray(img).resize(self.img_res))\n",
        "        img = np.expand_dims(img, axis=2)\n",
        "\n",
        "        if is_gt:\n",
        "            for not_l in self.not_labels:\n",
        "                img[img == not_l] = 0\n",
        "        return img\n",
        "\n",
        "    def _get_paths(self, stage):\n",
        "        if stage == 'train':\n",
        "            return self.train_patients\n",
        "        elif stage == 'valid':\n",
        "            return self.valid_patients\n",
        "        elif stage == 'test':\n",
        "            return self.test_patients\n",
        "\n",
        "    @background(max_prefetch=NUM_PREFETCH)\n",
        "    def get_random_batch(self, batch_size=1, stage='train'):\n",
        "        paths = self._get_paths(stage)\n",
        "\n",
        "        num = len(paths)\n",
        "        num_batches = num // batch_size\n",
        "\n",
        "        for i in range(num_batches):\n",
        "            batch_paths = np.random.choice(paths, size=batch_size)\n",
        "            target_imgs, condition_imgs, input_imgs, weight_imgs = self._get_batch(batch_paths, stage)\n",
        "            target_imgs = target_imgs * self.target_rescale\n",
        "            input_imgs = input_imgs * self.input_rescale\n",
        "            condition_imgs = condition_imgs * self.condition_rescale\n",
        "\n",
        "            yield target_imgs, condition_imgs, input_imgs, weight_imgs\n",
        "\n",
        "    def get_iterative_batch(self, batch_size=1, stage='test'):\n",
        "        paths = self._get_paths(stage)\n",
        "\n",
        "        num = len(paths)\n",
        "        num_batches = num // batch_size\n",
        "\n",
        "        start_idx = 0\n",
        "        for i in range(num_batches):\n",
        "            batch_paths = paths[start_idx:start_idx + batch_size]\n",
        "            target_imgs, condition_imgs, input_imgs, weight_imgs = self._get_batch(batch_paths, stage)\n",
        "            target_imgs = target_imgs * self.target_rescale\n",
        "            input_imgs = input_imgs * self.input_rescale\n",
        "            condition_imgs = condition_imgs * self.condition_rescale\n",
        "            start_idx += batch_size\n",
        "\n",
        "            yield target_imgs, condition_imgs, input_imgs, weight_imgs\n",
        "\n",
        "    def _get_batch(self, paths_batch, stage):\n",
        "        target_imgs = []\n",
        "        input_imgs = []\n",
        "        condition_imgs = []\n",
        "        weight_maps = []\n",
        "\n",
        "        for path in paths_batch:\n",
        "            transform = self.datagen.get_random_transform(img_shape=self.img_res)\n",
        "            head, patient_id = os.path.split(path)\n",
        "            target_path = os.path.join(path, '{}_{}.mhd'.format(patient_id, self.target_name))\n",
        "            condition_path = os.path.join(path, '{}_{}.mhd'.format(patient_id, self.condition_name))\n",
        "            input_path = os.path.join(path, '{}_{}.mhd'.format(patient_id, self.input_name))\n",
        "\n",
        "            input_img = self.read_mhd(input_path, '_gt' in self.input_name)\n",
        "            if self.augment['AUG_INPUT']:\n",
        "                input_img = self.datagen.apply_transform(input_img, transform)\n",
        "            input_imgs.append(input_img)\n",
        "\n",
        "            target_img = self.read_mhd(target_path, '_gt' in self.target_name)\n",
        "            condition_img = self.read_mhd(condition_path, 1)\n",
        "\n",
        "            if self.augment['AUG_TARGET']:\n",
        "                if not self.augment['AUG_SAME_FOR_BOTH']:\n",
        "                    transform = self.datagen.get_random_transform(img_shape=self.img_res)\n",
        "                target_img = self.datagen.apply_transform(target_img, transform)\n",
        "                condition_img = self.datagen.apply_transform(condition_img, transform)\n",
        "            target_imgs.append(target_img)\n",
        "            condition_imgs.append(condition_img)\n",
        "\n",
        "            weight_map_condition = self.get_weight_map(condition_img)\n",
        "            weight_maps.append(weight_map_condition)\n",
        "\n",
        "        return np.array(target_imgs), np.array(condition_imgs), np.array(input_imgs), np.array(weight_maps)\n",
        "\n",
        "    def get_weight_map(self, mask):\n",
        "        # let the y axis have higher variance\n",
        "        gauss_var = [[self.img_res[0] * 60, 0], [0, self.img_res[1] * 30]]\n",
        "        x, y = mask[:, :, 0].nonzero()\n",
        "        center = [x.mean(), y.mean()]\n",
        "\n",
        "        from scipy.stats import multivariate_normal\n",
        "        gauss = multivariate_normal.pdf(np.mgrid[\n",
        "                                        0:self.img_res[1],\n",
        "                                        0:self.img_res[0]].reshape(2, -1).transpose(),\n",
        "                                        mean=center,\n",
        "                                        cov=gauss_var)\n",
        "        gauss /= gauss.max()\n",
        "        gauss = gauss.reshape((self.img_res[1], self.img_res[0], 1))\n",
        "\n",
        "        # set the gauss value of the main target part to 1\n",
        "        gauss[mask > 0] = 1\n",
        "\n",
        "        return gauss\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hoNiDbdPC1fr"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import keras.backend as K\n",
        "\n",
        "plt.switch_backend('agg')\n",
        "\n",
        "\n",
        "def gen_fig(inputs, generated, targets):\n",
        "    r, c = 3, 3\n",
        "    titles = ['Condition', 'Generated', 'Original']\n",
        "    all_imgs = np.concatenate([inputs, generated, targets])\n",
        "\n",
        "    fig, axs = plt.subplots(r, c)\n",
        "    cnt = 0\n",
        "    for i in range(r):\n",
        "        for j in range(c):\n",
        "            axs[i, j].imshow(all_imgs[cnt, :, :, 0], cmap='gray')\n",
        "            axs[i, j].set_title(titles[i], fontdict={'fontsize': 8})\n",
        "            axs[i, j].axis('off')\n",
        "            cnt += 1\n",
        "    return fig\n",
        "\n",
        "\n",
        "def set_backend():\n",
        "    from keras.optimizers import tf\n",
        "    cf = tf.ConfigProto()\n",
        "    cf.gpu_options.allow_growth = True\n",
        "    sess = tf.Session(config=cf)\n",
        "    K.set_session(sess)\n",
        "\n",
        "\n",
        "def weighted_mae(weight_map):\n",
        "    def mae(y_true, y_pred):\n",
        "        return K.mean(K.abs(y_true - y_pred) * weight_map)\n",
        "    return mae\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cCTTMBPpC7Cj"
      },
      "source": [
        "\"\"\"\n",
        "The implementations of models are based on the pix2pix implementation of the Keras-GAN library:\n",
        "https://github.com/eriklindernoren/Keras-GAN/blob/master/pix2pix/pix2pix.py\n",
        "\"\"\"\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import reduce_sum\n",
        "from tensorflow.keras.backend import pow\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPool2D, UpSampling2D, Concatenate, Add, Flatten\n",
        "from tensorflow.keras.losses import binary_crossentropy\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.layers import Input, Dropout, Concatenate\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.layers.convolutional import Conv2DTranspose, Conv2D\n",
        "from keras.models import Model\n",
        "\n",
        "\n",
        "'''class UNetGenerator:\n",
        "    def __init__(self, img_shape, filters, channels, output_activation, skip_connections):\n",
        "        self.img_shape = img_shape\n",
        "        self.filters = filters\n",
        "        self.channels = channels\n",
        "        self.output_activation = output_activation\n",
        "        self.skip_connection = skip_connections\n",
        "\n",
        "    def build(self):\n",
        "        def conv2d(layer_input, filters, f_size=4, bn=True):\n",
        "            d = Conv2D(filters, kernel_size=f_size,\n",
        "                       strides=2, padding='same')(layer_input)\n",
        "            if bn:\n",
        "                d = BatchNormalization(momentum=0.8)(d)\n",
        "            d = LeakyReLU(alpha=0.2)(d)\n",
        "\n",
        "            return d\n",
        "\n",
        "        def deconv2d(layer_input, skip_input, filters, f_size=4, dropout_rate=0):\n",
        "            u = Conv2DTranspose(filters, kernel_size=f_size, strides=(2, 2),\n",
        "                                padding='same', activation='linear')(layer_input)\n",
        "            u = Conv2D(filters, kernel_size=f_size, strides=1,\n",
        "                       padding='same', activation='relu')(u)\n",
        "\n",
        "            u = BatchNormalization(momentum=0.8)(u)\n",
        "            if dropout_rate:\n",
        "                u = Dropout(dropout_rate)(u)\n",
        "            if self.skip_connection:\n",
        "                u = Concatenate()([u, skip_input])\n",
        "\n",
        "            return u\n",
        "\n",
        "        # Image input\n",
        "        d0 = Input(shape=self.img_shape)\n",
        "\n",
        "        # Downsampling: 7 x stride of 2 --> x1/128 downsampling\n",
        "        d1 = conv2d(d0, self.filters, bn=False)\n",
        "        d2 = conv2d(d1, self.filters * 2)\n",
        "        d3 = conv2d(d2, self.filters * 4)\n",
        "        d4 = conv2d(d3, self.filters * 8)\n",
        "        d5 = conv2d(d4, self.filters * 8)\n",
        "        d6 = conv2d(d5, self.filters * 8)\n",
        "        d7 = conv2d(d6, self.filters * 8)\n",
        "\n",
        "        # Upsampling: 6 x stride of 2 --> x64 upsampling\n",
        "        u1 = deconv2d(d7, d6, self.filters * 8)\n",
        "        u2 = deconv2d(u1, d5, self.filters * 8)\n",
        "        u3 = deconv2d(u2, d4, self.filters * 8)\n",
        "        u4 = deconv2d(u3, d3, self.filters * 4)\n",
        "        u5 = deconv2d(u4, d2, self.filters * 2)\n",
        "        u6 = deconv2d(u5, d1, self.filters)\n",
        "        u7 = Conv2DTranspose(self.channels, kernel_size=4, strides=(2, 2),\n",
        "                             padding='same', activation='linear')(u6)\n",
        "\n",
        "        # added conv layers after the deconvs to avoid the pixelated outputs\n",
        "        output_img = Conv2D(self.channels, kernel_size=4,\n",
        "                            strides=1, padding='same',\n",
        "                            activation=self.output_activation)(u7)\n",
        "\n",
        "        return Model(d0, output_img)'''\n",
        "\n",
        "\n",
        "class RESUnet:\n",
        "    def __init__(self, img_shape, filters, channels, output_activation, skip_connections):\n",
        "        self.img_shape = img_shape\n",
        "        self.filters = filters\n",
        "        self.channels = channels\n",
        "        self.output_activation = output_activation\n",
        "        self.skip_connection = skip_connections    \n",
        "\n",
        "    def build(self):\n",
        "        def bn_act(x, act=True):\n",
        "            x = tf.keras.layers.BatchNormalization()(x)\n",
        "            if act == True:\n",
        "                x = tf.keras.layers.Activation('relu')(x)\n",
        "            return x\n",
        "\n",
        "        #convolutional layer, always uses the batch normalization layer\n",
        "        def conv_block(x, filters, kernel_size=3, padding='same', strides=1):\n",
        "            conv = bn_act(x)\n",
        "            conv = Conv2D(filters, kernel_size, padding=padding, strides=strides)(conv)\n",
        "            return conv\n",
        "\n",
        "        def stem(x, filters, kernel_size=3, padding='same', strides=1):\n",
        "            conv = Conv2D(filters, kernel_size, padding=padding, strides=strides)(x)\n",
        "            conv = conv_block(conv, filters, kernel_size, padding, strides)\n",
        "            shortcut = Conv2D(filters, kernel_size=1, padding=padding, strides=strides)(x)\n",
        "            shortcut = bn_act(shortcut, act=False)\n",
        "            output = Add()([conv, shortcut])\n",
        "            return output\n",
        "\n",
        "        #Residual block/unit from Resnet with binary normalization as skip connection\n",
        "        def residual_block(x, filters, kernel_size=3, padding='same', strides=1):\n",
        "            res = conv_block(x, filters, k_size, padding, strides)\n",
        "            res = conv_block(res, filters, k_size, padding, 1)\n",
        "            shortcut = Conv2D(filters, kernel_size, padding=padding, strides=strides)(x)\n",
        "            shortcut = bn_act(shortcut, act=False)\n",
        "            output = Add()([shortcut, res])\n",
        "            return output\n",
        "\n",
        "        #upsampling block (Decoder path)\n",
        "        def upsample_concat_block(x, xskip):\n",
        "            u = UpSampling2D((2,2))(x)\n",
        "            c = Concatenate()([u, xskip])\n",
        "            return c\n",
        "\n",
        "        #ResUNet model\n",
        "        def ResUNet(img_h, img_w):\n",
        "            f = [16, 32, 64, 128, 256]\n",
        "            inputs = Input((img_h, img_w, 1))\n",
        "            \n",
        "            ## Encoder\n",
        "            e0 = inputs\n",
        "            e1 = stem(e0, f[0])\n",
        "            e2 = residual_block(e1, f[1], strides=2)\n",
        "            e3 = residual_block(e2, f[2], strides=2)\n",
        "            e4 = residual_block(e3, f[3], strides=2)\n",
        "            e5 = residual_block(e4, f[4], strides=2)\n",
        "            \n",
        "            ## Bridge\n",
        "            b0 = conv_block(e5, f[4], strides=1)\n",
        "            b1 = conv_block(b0, f[4], strides=1)\n",
        "            \n",
        "            ## Decoder\n",
        "            u1 = upsample_concat_block(b1, e4)\n",
        "            d1 = residual_block(u1, f[4])\n",
        "            \n",
        "            u2 = upsample_concat_block(d1, e3)\n",
        "            d2 = residual_block(u2, f[3])\n",
        "            \n",
        "            u3 = upsample_concat_block(d2, e2)\n",
        "            d3 = residual_block(u3, f[2])\n",
        "            \n",
        "            u4 = upsample_concat_block(d3, e1)\n",
        "            d4 = residual_block(u4, f[1])\n",
        "            \n",
        "            outputs = tf.keras.layers.Conv2D(4, (1, 1), padding=\"same\", activation=\"sigmoid\")(d4)\n",
        "            model = tf.keras.models.Model(inputs, outputs)\n",
        "            return model\n",
        "\n",
        "    def dsc(y_true, y_pred):\n",
        "        smooth = 1.\n",
        "        y_true_f = Flatten()(y_true)\n",
        "        y_pred_f = Flatten()(y_pred)\n",
        "        intersection = reduce_sum(y_true_f * y_pred_f)\n",
        "        score = (2. * intersection + smooth) / (reduce_sum(y_true_f) + reduce_sum(y_pred_f) + smooth)\n",
        "        return score\n",
        "\n",
        "    def dice_loss(y_true, y_pred):\n",
        "        loss = 1 - dsc(y_true, y_pred)\n",
        "        return loss\n",
        "\n",
        "    def bce_dice_loss(y_true, y_pred):\n",
        "        loss = binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)\n",
        "        return loss\n",
        "\n",
        "    \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yTsBtN_PC_5M",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "outputId": "621d089c-4c09-4cee-b240-9c70b46f1f39"
      },
      "source": [
        "import json\n",
        "from absl import app\n",
        "from absl import flags\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#from data_loader_camus import DataLoaderCamus\n",
        "#from models import RESUnet;\n",
        "#from utils import set_backend\n",
        "\n",
        "\n",
        "flags.DEFINE_string('dataset_path', \"/content/drive/My Drive/Neural Network Dataset/\", 'Path of the dataset.')\n",
        "flags.DEFINE_boolean('test', False, 'Test model and generate outputs on the test set')\n",
        "flags.DEFINE_string('config', \"configs/ventricle.json\", 'Config file for training hyper-parameters.')\n",
        "flags.DEFINE_boolean('use_wandb', False, 'Use wandb for logging')\n",
        "flags.DEFINE_string('ckpt_load', None, 'Path to load the model')\n",
        "flags.DEFINE_float('train_ratio', 0.95,\n",
        "                   'Ratio of training data used for training and the rest used for testing. Set this value to 1.0 if '\n",
        "                   'the data in the test folder are to be used for testing.')\n",
        "flags.DEFINE_float('valid_ratio', 0.02, 'Ratio of training data used for validation')\n",
        "\n",
        "#FLAGS = flags.FLAGS\n",
        "\n",
        "\n",
        "plt.switch_backend('agg')\n",
        "\n",
        "\n",
        "def main(argv):\n",
        "    # Load configs from file\n",
        "    config = json.load(open(FLAGS.config))\n",
        "    set_backend()\n",
        "\n",
        "    # Set name\n",
        "    name = '{}_{}_'.format(config['INPUT_NAME'], config['TARGET_NAME'])\n",
        "    for l in config['LABELS']:\n",
        "        name += str(l)\n",
        "    config['NAME'] += '_' + name\n",
        "\n",
        "    # Organize augmentation hyper-parameters from config\n",
        "    augmentation = dict()\n",
        "    for key, value in config.items():\n",
        "        if 'AUG_' in key:\n",
        "            augmentation[key] = value\n",
        "\n",
        "    # Initialize data loader\n",
        "    data_loaderED = DataLoaderCamus(\n",
        "        dataset_path=FLAGS.dataset_path,\n",
        "        input_name=config['INPUT_NAME'],\n",
        "        target_name=config['TARGET_NAME'],\n",
        "        condition_name=config['CONDITION_NAME'],\n",
        "        img_res=config['IMAGE_RES'],\n",
        "        target_rescale=config['TARGET_TRANS'],\n",
        "        input_rescale=config['INPUT_TRANS'],\n",
        "        condition_rescale=config['CONDITION_TRANS'],\n",
        "        labels=config['LABELS'],\n",
        "        train_ratio=FLAGS.train_ratio,\n",
        "        valid_ratio=FLAGS.valid_ratio,\n",
        "        augment=augmentation\n",
        "    )\n",
        "\n",
        "    data_loaderES = DataLoaderCamus(\n",
        "        dataset_path=FLAGS.dataset_path,\n",
        "        input_name=\"4CH_ES_gt\",\n",
        "        target_name=\"4CH_ES\",\n",
        "        condition_name=\"4CH_ES_gt\",\n",
        "        img_res=config['IMAGE_RES'],\n",
        "        target_rescale=config['TARGET_TRANS'],\n",
        "        input_rescale=config['INPUT_TRANS'],\n",
        "        condition_rescale=config['CONDITION_TRANS'],\n",
        "        labels=config['LABELS'],\n",
        "        train_ratio=FLAGS.train_ratio,\n",
        "        valid_ratio=FLAGS.valid_ratio,\n",
        "        augment=augmentation\n",
        "    )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # build model for ED\n",
        "    #model = EjectionFraction(data_loader, config, FLAGS.use_wandb)\n",
        "    modelED = RESUNet(self.img_shape, self.df, self.channels, self.output_activation, self.skipconnections_generator).build()\n",
        "    adam = tf.keras.optimizers.Adam(lr = 0.01, epsilon = 0.1)\n",
        "    modelED.compile(optimizer=adam, loss=bce_dice_loss, metrics=[dsc])\n",
        "    #modelED.summary() # print out the architecture of our network\n",
        "\n",
        "    # build model for ES\n",
        "    #model = EjectionFraction(data_loader, config, FLAGS.use_wandb)\n",
        "    modelES = RESUNet(self.img_shape, self.df, self.channels, self.output_activation, self.skipconnections_generator).build()\n",
        "    adam = tf.keras.optimizers.Adam(lr = 0.01, epsilon = 0.1)\n",
        "    modelES.compile(optimizer=adam, loss=bce_dice_loss, metrics=[dsc])\n",
        "    #modelES.summary() # print out the architecture of our network\n",
        "\n",
        "\n",
        "    # load a pre trained model here if you wish\n",
        "    # model.load_weights('../input/resunet-e200-s256/ResUNet.h5')\n",
        "\n",
        "    # running more epoch to see if we can get better results\n",
        "    historyED = modelED.fit_generator(generator=training_generator, validation_data=validation_generator, epochs=10, verbose=1)\n",
        "    historyES = modelES.fit_generator(generator=training_generator, validation_data=validation_generator, epochs=10, verbose=1)\n",
        "\n",
        "    # list all data in history\n",
        "    print(history.history.keys())\n",
        "    # summarize history for accuracy\n",
        "    plt.figure(figsize=(20,5))\n",
        "    plt.subplot(1,2,1)\n",
        "    plt.plot(history.history['dsc'])\n",
        "    plt.plot(history.history['val_dsc'])\n",
        "    plt.title('model accuracy')\n",
        "    plt.ylabel('accuracy')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'test'], loc='upper left')\n",
        "\n",
        "    # summarize history for loss\n",
        "    plt.subplot(1,2,2)\n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.plot(history.history['val_loss'])\n",
        "    plt.title('model loss')\n",
        "    plt.ylabel('loss')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'test'], loc='upper left')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # load trained models if they exist\n",
        "    if FLAGS.ckpt_load is not None:\n",
        "        model.load_model(FLAGS.ckpt_load)\n",
        "\n",
        "    if FLAGS.test:\n",
        "        model.test()\n",
        "    else:\n",
        "        model.train()\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    app.run(main)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "DuplicateFlagError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mDuplicateFlagError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-ca7005abbe80>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m#flags.DEFINE_string('dataset_path', \"/content/drive/My Drive/Neural Network Dataset/\", 'Path of the dataset.')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDEFINE_boolean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Test model and generate outputs on the test set'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDEFINE_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'config'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"configs/ventricle.json\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Config file for training hyper-parameters.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDEFINE_boolean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'use_wandb'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Use wandb for logging'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/absl/flags/_defines.py\u001b[0m in \u001b[0;36mDEFINE_boolean\u001b[0;34m(name, default, help, flag_values, module_name, **args)\u001b[0m\n\u001b[1;32m    266\u001b[0m   \"\"\"\n\u001b[1;32m    267\u001b[0m   DEFINE_flag(_flag.BooleanFlag(name, default, help, **args),\n\u001b[0;32m--> 268\u001b[0;31m               flag_values, module_name)\n\u001b[0m\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/absl/flags/_defines.py\u001b[0m in \u001b[0;36mDEFINE_flag\u001b[0;34m(flag, flag_values, module_name)\u001b[0m\n\u001b[1;32m    102\u001b[0m   \u001b[0;31m# Copying the reference to flag_values prevents pychecker warnings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m   \u001b[0mfv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflag_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m   \u001b[0mfv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mflag\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m   \u001b[0;31m# Tell flag_values who's defining the flag.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/absl/flags/_flagvalues.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, name, flag)\u001b[0m\n\u001b[1;32m    428\u001b[0m         \u001b[0;31m# module is simply being imported a subsequent time.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0m_exceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDuplicateFlagError\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_flag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m     \u001b[0mshort_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshort_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m     \u001b[0;31m# If a new flag overrides an old one, we need to cleanup the old flag's\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mDuplicateFlagError\u001b[0m: The flag 'test' is defined twice. First from /usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py, Second from /usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py.  Description from first occurrence: Test model and generate outputs on the test set"
          ]
        }
      ]
    }
  ]
}